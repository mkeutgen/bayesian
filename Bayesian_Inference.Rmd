---
title: "Bayesian Inference"
output: html_notebook
author: "Maxime Keutgen"
---
## Introduction

This is an R notebook about Bayesian Inference. Let's start with an example. We are conducting a study on heart strokes. Historical studies show complication SICH. We want to estimate risk for SICH in ECASS 3. We have prior informations from two studies : ECASS 1 and ECASS 2, ECASS 2 says proportion of patients with SICH is $ 8/100 $.

The first preliminary results, in ECASS 3, tell us that out of 50 patients with strokes, 10 are affected by the SICH complication.

### Notation : 
 
* SICH incidence : $\theta$
* i.i.d Bernouilli rvs : $y_1,...,y_n$
* SICH : $y_1 = 1$, 0 otherwise.
* $y = \sum^{n}_{i=1} y_i \sim Bin(n,\theta)$
* $p(y|\theta) = {N\choose\theta} \theta^y (1-\theta)^{n-y}$

## The Frequentist paradigm

Let's get back for a moment to the good old frequentist paradigm. In this paradigm, we do not use any prior informations (asymptotic goes brrrr). For a binomially distributed random variable, the MLE for $\theta$ is obtained from the likelihood function : 
$$ \hat{\theta} = \arg\max_\theta \left[ \left[ \prod_i^n {{N}\choose{y_i}} \right] \theta^{\sum_1^n y_i} (1-\theta)^{nN - \sum_1^n{y_i}}\right] $$

Which yiels an MLE of :
$$ \hat{\theta} = \frac{\bar{y}}{N}  $$
Trivially, number of successes on total number of trials is the MLE estimator of theta for a binomially distributed random variable. Hence, in our exemple with only 10 patients with SICH out of 50 patients with stroke, theta hat is 
$$ \hat{\theta} = 1/5 $$
ECASS 2 study claimed that the proportion of patients with SICH was 0.09. Let's construct a $95 \%$ CI for the MLE we obtained. We know that :

$$ \sqrt{n}\left(\hat{\theta}-\theta_0\right) \rightarrow \mathcal{N}\left(0,\frac{1}{\mathcal{I}_1(\theta_0)}\right)$$
And that $\mathcal{I}_1(\theta_0)$ is the Fisher information which is equal to $\frac{n}{\theta(1-\theta)} $

Therefore, in this example, the Fisher information is :
$$\mathcal{I}_1(\theta_0) = \frac{50}{0.2 \times 0.8}$$
Thus a 95 \% confidence interval can be found whose upper and lowers are bounds are :
$$ +/- \frac{1.96}  {\sqrt n \times \mathcal{I}_1(\hat{\theta}) }$$
Here, this corresponds to 0.2 +/- 0.1568. The assumption of normality on which this rely is often violated. Likelihood approach. We can also use the Wald method is preferred :
$$ \hat{\theta} +/- z \sqrt \frac{\hat{\theta}(1-\hat{\theta})}{n} $$
This produces a confidence interval of 0.2 +/- 0.11

## Bayesian approach

In the Bayesian approach, we _use_ prior information. We start by : 

* Specifying the (ECASS 2) prior distribution
* Constructing the posterior distribution
* Characteristics of the posterior distribution
* Equivalence of prior information and extra data

### Specifying the prior distribution
Okay kids, let's start with the likelihood function we've shown earlier :
$$ L(\theta|y_0) = {n_0\choose y_0} \theta^{y_0} (1-\theta)^{n_0-y_0} $$
Altough this function does provide valuable information about the likelihood of a parameter theta having  _prior_ belief theta (because y_0 and n_0 can be from a prior study), this likelihood function is obviously not a pdf. Indeed, its integral from -Inf to +Inf is not equal to 1.

However, if we remind ourselves of the second Likelihood Principle :

" _Two likelihood functions for θ contain the same information about θ if they
are proportional to each other_ "




```{r}

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Ctrl+Alt+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Ctrl+Shift+K* to preview the HTML file).

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

```{r}

```

